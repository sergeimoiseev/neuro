{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('uoit': conda)"
  },
  "interpreter": {
   "hash": "26d424bfc1230b0c30211611c2aa3c9b9b27c0aba4441f1e20f124f124483991"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "# test_data = pd.read_csv('test.csv') # тестовый набор нельзя использовать: нет колонки SalePrice\n",
    "# позже раздробим data на обучающуюся и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfull = data.SalePrice\n",
    "Xfull = data.drop( labels = [\"SalePrice\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.dropna(axis='columns')\n",
    "#Находим категориальные признаки\n",
    "cat_feat = list(Xfull.dtypes[Xfull.dtypes == object].index)\n",
    "\n",
    "#отфильтруем непрерывные признаки\n",
    "num_feat = [f for f in Xfull if f not in (cat_feat + ['Id'])]\n",
    "\n",
    "# Создаем дамми-переменные для категорий\n",
    "X_dummies = pd.get_dummies(Xfull[cat_feat], columns=cat_feat)\n",
    "# dummy_test = pd.get_dummies(X_test[cat_feat], columns=cat_feat)\n",
    "\n",
    "dummy_cols = list(set(X_dummies))\n",
    "\n",
    "X_dummies = X_dummies[dummy_cols]\n",
    "# dummy_test = dummy_test[dummy_cols]\n",
    "\n",
    "# Заменяем пропуски на специальное значение -999, чтобы деревья могли их отличить\n",
    "Xfull = pd.concat([Xfull[num_feat].fillna(-999),\n",
    "                     X_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем holdout-выборку \n",
    "X, Xhold, y, yhold = train_test_split(\n",
    "    Xfull, yfull, random_state=42\n",
    ")\n",
    "X = X.reindex()\n",
    "Xhold = Xhold.reindex()\n",
    "y = y.reindex()\n",
    "yhold = yhold.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1095 entries, 1023 to 1126\nColumns: 288 entries, MSSubClass to Exterior2nd_VinylSd\ndtypes: float64(3), int64(33), uint8(252)\nmemory usage: 586.0 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random forest score:\n0.8584423166903885\nFeature importances\n[1.05217634e-03 6.38344586e-03 1.47326428e-02 5.85745989e-01\n 4.34758552e-03 8.90450803e-03 5.48484583e-03 8.39705994e-03\n 2.63260122e-02 3.56474846e-04 6.13197583e-03 4.14047794e-02\n 2.37182101e-02 4.73209430e-02 1.03779226e-04 9.70216345e-02\n 9.79696573e-04 5.83049600e-04 4.54187153e-03 4.94770298e-04\n 2.16258219e-03 8.10988998e-04 6.51552552e-03 2.35319310e-03\n 6.30720821e-03 2.12949139e-02 1.34653807e-02 4.52374682e-03\n 3.67127812e-03 5.14938164e-04 2.75382285e-04 7.33119659e-04\n 5.94037079e-06 3.50772745e-05 3.68347409e-03 1.26851995e-03\n 1.20156839e-04 3.14246537e-04 4.14538149e-04 9.78342397e-06\n 1.31952911e-04 6.30086164e-06 3.20077366e-05 1.90037559e-05\n 4.75180479e-06 1.77680687e-07 2.64632704e-04 4.87693199e-06\n 1.03221550e-04 5.37073130e-04 5.57753963e-05 2.51813641e-05\n 3.71050306e-06 7.57310332e-04 1.60309097e-04 2.90046813e-07\n 7.76259140e-08 2.67241510e-04 4.55174598e-04 4.58703256e-05\n 2.54446462e-04 2.74590133e-05 1.24436529e-05 1.35949240e-04\n 7.47088331e-04 2.37459644e-04 4.48842148e-05 1.40807796e-04\n 1.81997112e-04 3.00041522e-04 2.21295300e-05 1.88767011e-04\n 4.65531581e-04 9.85125829e-05 8.19553079e-04 6.96829978e-05\n 3.07528965e-04 2.06188507e-04 3.06024112e-04 6.91534628e-05\n 0.00000000e+00 2.48262631e-04 7.77861476e-05 1.91832631e-04\n 4.87686866e-05 2.70546755e-05 1.88745625e-03 1.13660860e-04\n 9.97043440e-05 6.84547577e-05 3.62775426e-04 2.33624658e-06\n 4.47366174e-07 5.53155291e-04 1.54203928e-04 2.45596991e-05\n 4.60676860e-07 4.68097421e-04 1.52918572e-05 4.34503036e-04\n 1.26414884e-04 2.71505757e-04 8.59967107e-05 1.72281774e-04\n 2.93567618e-04 1.84266272e-04 1.45479868e-04 2.74514292e-06\n 3.85028259e-04 8.99502104e-05 2.02047316e-05 8.41438310e-06\n 3.81030499e-06 1.75516157e-09 4.88475472e-05 2.43995180e-05\n 1.37105085e-04 1.88043739e-06 9.91096315e-06 4.07922723e-06\n 6.83756949e-05 4.80567138e-06 1.32333030e-03 5.39230731e-07\n 1.43776659e-04 3.64177221e-07 2.61572949e-05 3.16952716e-07\n 6.42781177e-05 3.29687261e-04 4.88291157e-07 1.50000197e-05\n 1.45214610e-03 7.95343143e-04 2.38032614e-05 7.70171447e-05\n 1.65192484e-05 2.38636638e-07 7.65570694e-06 6.85587802e-06\n 7.58285672e-05 1.25832441e-05 1.29070114e-05 3.87152547e-06\n 6.59806805e-05 2.32647485e-04 8.34154976e-04 4.67988119e-05\n 9.00088243e-05 1.95670661e-05 1.99683492e-06 9.70552603e-05\n 1.10952022e-04 1.67664731e-03 1.22095903e-04 4.06201156e-08\n 1.55004564e-05 3.38632353e-04 6.02844596e-05 1.42993007e-04\n 8.87543289e-06 3.77577096e-04 1.67700284e-04 1.60343678e-04\n 6.39902219e-04 9.82638626e-05 1.40286294e-04 1.74007494e-04\n 2.48180932e-04 1.72039517e-04 2.48573192e-05 1.11715739e-04\n 3.35329704e-05 3.96028389e-04 2.34119738e-06 9.52494931e-04\n 2.67110668e-06 4.49069612e-04 1.93112115e-04 5.60623400e-07\n 3.05106170e-05 7.76255041e-05 1.51565978e-08 7.69284353e-07\n 8.45329768e-05 5.39781206e-08 5.81065573e-07 3.12056214e-04\n 2.68743258e-04 5.55446380e-05 1.07599646e-04 2.28291325e-08\n 4.00717749e-05 5.24882233e-05 1.12577939e-03 9.88565828e-06\n 1.71366611e-04 0.00000000e+00 7.12880737e-05 4.01897512e-05\n 5.63005589e-07 5.78628263e-07 1.83946080e-05 6.58049928e-06\n 2.27693135e-04 8.99400017e-05 3.48555068e-04 1.00797448e-03\n 3.05532381e-07 5.63168130e-07 5.47412477e-04 6.78543336e-09\n 6.05802273e-05 3.91671692e-08 3.11081106e-04 7.44290848e-05\n 3.52477174e-05 6.85150178e-05 4.64373505e-05 3.07162695e-04\n 4.38416611e-04 2.68722673e-04 2.94978186e-04 8.90094168e-05\n 4.86226572e-04 4.35803678e-05 2.52779214e-05 7.21471121e-05\n 8.25030259e-05 7.28103870e-05 7.86780147e-04 1.56429639e-04\n 1.14919181e-07 1.46454835e-05 2.38496149e-04 3.62380113e-05\n 0.00000000e+00 2.32109494e-04 1.47769294e-04 4.09873682e-05\n 2.32572862e-04 1.72485205e-05 7.10074614e-07 3.96974182e-03\n 6.56369715e-06 7.11515342e-06 6.07456745e-04 1.56727054e-04\n 7.77319512e-06 2.99202359e-04 2.02153654e-05 1.03290242e-04\n 6.41036278e-06 4.70966830e-05 7.48071596e-05 8.03992792e-07\n 1.38208595e-04 2.62922103e-08 1.03998973e-04 5.79120087e-05\n 1.03222291e-03 1.01338670e-05 3.07691527e-06 3.80864772e-04\n 6.98212611e-07 1.21113827e-05 2.26241019e-04 1.68977370e-08\n 3.75956623e-05 1.28946882e-04 2.32926579e-06 6.06164150e-04\n 1.80886954e-04 2.97238356e-05 8.05700940e-04 5.56537354e-06\n 2.81648594e-06 4.43572035e-05 4.19410567e-04 3.59553399e-06\n 6.28350058e-04 4.24734284e-05 2.18151288e-05 9.58782310e-10\n 2.42445204e-05 6.71278265e-06 1.64683629e-04 7.05410534e-04]\n"
     ]
    }
   ],
   "source": [
    "# беру один фолд из 10 и строю на нем случайный лес, вывожу важность признаков.\n",
    "# эдакая тренировка перед стекингом\n",
    "# чуть поправил взятое отсюда\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(Xfull):\n",
    "    rf = RandomForestRegressor(verbose=False, n_jobs=-1)\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = Xfull.iloc[train_index], Xfull.iloc[test_index]\n",
    "    y_train, y_test = yfull[train_index], yfull[test_index]\n",
    "    rf.fit(X_train,y_train)\n",
    "    print(\"Random forest score:\")\n",
    "    print(rf.score(X_test,y_test))\n",
    "    print(\"Feature importances\")\n",
    "    print(rf.feature_importances_)\n",
    "    break # берем только один эксперимент, чтобы не заниматься никаким ансамблированием сейчас\n",
    "# если нужны усредненные по k-фолдам значимости параметров, можно сделать усреднением. Но не вижу смысла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8659944711082004"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# кроссвалидация одного только случайного леса - переработаный код отсюда:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "cv_results = cross_validate(rf, Xfull, yfull, cv=10)\n",
    "# sorted(cv_results.keys())\n",
    "all_scores = cv_results['test_score']\n",
    "from statistics import mean\n",
    "# средний score по 10и фолдам для случайного леса:\n",
    "mean(all_scores)\n",
    "# тоже смысла не вижу - случайный лес внутри уже делит выборку \n",
    "# в итоге у каждого из деревьев совсем мало данных, \n",
    "# оттого, наверное, и score ниже чем у простого случайного леса ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8891397357874941\n[2.10259687e-03 7.63572525e-03 1.74936362e-02 5.51684361e-01\n 4.11054859e-03 1.16985357e-02 6.20743493e-03 3.82605725e-03\n 2.95525482e-02 6.17067512e-04 4.77838697e-03 3.18086636e-02\n 2.35479620e-02 2.49892103e-02 4.89140077e-05 1.21689087e-01\n 6.49679585e-04 9.40679709e-05 7.52316105e-03 8.11740326e-04\n 1.07274069e-03 2.99312343e-04 6.54957781e-03 4.20937210e-03\n 7.49428573e-03 2.02780508e-02 1.58549054e-02 4.65439618e-03\n 4.68366275e-03 7.44613784e-04 6.91944030e-05 3.17285321e-03\n 9.57210023e-04 4.82861617e-05 3.96431110e-03 1.36922559e-03\n 3.65464545e-04 8.83060083e-04 4.22165117e-04 6.67635259e-05\n 3.38510102e-04 1.16561174e-06 2.79663244e-05 7.28317148e-06\n 3.70022990e-05 4.57918512e-06 2.02974927e-04 4.91897212e-05\n 4.02602522e-04 5.12651867e-04 4.93355196e-05 3.25939699e-05\n 6.72251501e-06 3.54365616e-04 4.79021689e-04 2.76299620e-09\n 6.35905527e-08 4.81005665e-04 8.65709074e-04 7.56013351e-05\n 4.31092850e-04 1.14604509e-04 1.00761239e-05 1.87872028e-04\n 7.72700933e-04 3.37443434e-04 3.61298446e-05 1.13711162e-04\n 5.10140346e-04 5.69428298e-04 1.86553705e-06 1.38042668e-04\n 6.85320662e-04 6.57012212e-05 3.24709246e-04 4.91040477e-05\n 3.57115079e-04 4.41011969e-04 1.11016202e-03 5.09596181e-05\n 1.00300640e-05 2.63814020e-04 1.65327326e-04 1.04527240e-04\n 5.23795618e-05 2.38032689e-06 1.54355440e-03 1.76175070e-04\n 7.32067487e-05 5.04027139e-05 4.38642718e-04 1.02832512e-05\n 6.98065916e-09 6.85805529e-04 3.84672024e-04 5.70686089e-05\n 4.77598076e-06 7.38305995e-04 4.78310856e-05 3.33428267e-04\n 4.59472374e-04 3.55071382e-04 1.83195455e-04 2.25567721e-04\n 2.19507425e-04 1.86342344e-04 7.13433482e-04 3.59690256e-06\n 6.77305281e-04 1.76756842e-04 1.65703290e-05 2.60013456e-05\n 1.07190027e-06 0.00000000e+00 1.69731097e-05 3.93412679e-05\n 6.22487735e-05 2.44427171e-05 6.88616955e-07 1.70897978e-10\n 6.14073505e-05 3.58714571e-05 1.88925007e-03 5.19579028e-07\n 2.97584266e-04 4.87061667e-05 5.84186778e-05 1.03445576e-06\n 3.44182657e-05 2.26181228e-04 0.00000000e+00 1.53734813e-05\n 2.16989654e-03 1.66842724e-03 0.00000000e+00 3.12544075e-05\n 6.35219589e-05 5.17717917e-08 2.67220626e-06 3.98637976e-06\n 1.09932089e-04 1.91489702e-05 1.12439111e-05 2.17783935e-05\n 4.84112145e-05 2.03251630e-04 1.08843057e-03 8.43609872e-05\n 9.80080478e-05 1.25774169e-05 1.01512727e-04 1.17312050e-04\n 1.01318474e-04 3.20770501e-03 6.13663291e-05 0.00000000e+00\n 2.87893708e-05 1.64242629e-04 4.25008827e-05 2.92238543e-04\n 1.14058316e-05 4.59574561e-04 1.96881431e-04 1.04733856e-04\n 1.05250673e-03 1.34806908e-04 2.62208651e-04 1.57087885e-04\n 6.80867574e-04 2.89487944e-04 2.22622178e-05 3.42497887e-04\n 3.65859043e-05 9.16192804e-04 4.76515164e-06 1.05327289e-03\n 2.62981119e-07 6.47160096e-04 2.48498484e-04 0.00000000e+00\n 4.22207989e-06 5.74232302e-05 0.00000000e+00 1.48596731e-06\n 7.12028473e-05 1.05888971e-06 0.00000000e+00 4.24532793e-04\n 3.42137575e-04 3.86657213e-05 1.16902697e-04 9.72058331e-08\n 7.03019099e-05 3.28770712e-05 7.51228620e-04 2.38605666e-06\n 1.91397937e-04 6.85752291e-09 4.25151894e-05 1.70777437e-05\n 1.39496213e-06 2.00725512e-06 3.75893901e-05 0.00000000e+00\n 2.90752579e-04 1.13979905e-04 4.09676080e-04 1.53461466e-03\n 1.02275724e-06 1.27813334e-06 4.11819357e-04 4.61064175e-06\n 1.72644201e-05 3.60913849e-06 3.22803982e-04 1.65955592e-04\n 6.80551444e-05 5.50430067e-05 5.15191687e-05 6.24728595e-04\n 5.06002700e-04 3.05029577e-04 3.25731433e-04 1.30234126e-04\n 2.23380395e-04 4.33291022e-05 3.09100602e-06 9.98456757e-05\n 6.87103472e-05 1.04155626e-04 1.76548114e-03 1.20354677e-04\n 1.00482548e-03 7.53205348e-06 3.32702692e-04 3.58913351e-05\n 4.53156344e-07 2.91804854e-04 7.82131336e-05 1.70746589e-05\n 2.43303311e-04 7.63204007e-06 3.55080236e-06 8.90240161e-03\n 6.63082413e-07 1.29877680e-05 6.46653761e-04 9.35742038e-05\n 7.34688078e-08 4.54935764e-04 2.14409390e-05 1.56444766e-04\n 2.35766758e-05 2.33655084e-06 7.01886822e-05 0.00000000e+00\n 3.73957673e-04 7.79292808e-08 1.35772268e-04 1.10394767e-04\n 3.08652951e-03 1.35325028e-05 7.75500883e-05 4.87157914e-04\n 2.18119779e-07 1.52463653e-04 1.63433468e-04 0.00000000e+00\n 4.12392392e-06 3.47978116e-05 2.04276426e-06 6.20069404e-04\n 2.93677856e-04 2.89304367e-06 3.88085008e-03 5.87037513e-06\n 9.62088335e-10 5.18589248e-05 7.24788141e-04 2.29104849e-05\n 8.87109826e-04 2.48728526e-05 1.61633148e-05 1.12530540e-06\n 7.69586370e-05 1.92296789e-09 2.10708255e-04 3.12891375e-04]\n"
     ]
    }
   ],
   "source": [
    "# Один случайный лес - учим на всем, кроме holdout, проверяем на holdout.\n",
    "# Плюс выводим важность признаков\n",
    "# Интересно, насколько скор будет отличаться у cv и такого подхода \n",
    "one_rf = RandomForestRegressor(verbose=False, n_jobs=-1)\n",
    "one_rf.fit(X,y)\n",
    "print(one_rf.score(Xhold,yhold))\n",
    "print(one_rf.feature_importances_)\n",
    "# скор получился тут су"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8679951319689396"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "# на трех моделях строим стекинг, \n",
    "# а потом считаем скор каждой из них в отдельности\n",
    "# непонятно, как правильно совмещать кросвалидацию и holdout. \n",
    "# для меня это два независимых способа оценки качества обучения.estimators\n",
    "\n",
    "# отсюда код взят и доработан\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html?highlight=regressor#sklearn.ensemble.StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV, SGDRegressor, LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# X, y = load_diabetes(return_X_y=True)\n",
    "estimators = [\n",
    "    ('rcv', RidgeCV()),\n",
    "    ('svr', LinearSVR(random_state=42)),\n",
    "    ('lr', LinearRegression())\n",
    "    # ('sgd', SGDRegressor(random_state=42))\n",
    "]\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(random_state=42),\n",
    "    cv=10,\n",
    ")\n",
    "\n",
    "reg.fit(X, y).score(Xhold, yhold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimator: \n",
      "rcv\n",
      "cross_val score: \n",
      "[0.91089043 0.90884634 0.89996691 0.78113865 0.88449541 0.88597101\n",
      " 0.86924554 0.88814094 0.56787695 0.88265082]\n",
      "cross_val mean score: \n",
      "0.84792230118371\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "Estimator: \n",
      "svr\n",
      "cross_val score: \n",
      "[0.80158092 0.77074654 0.82657469 0.66400414 0.76824609 0.76226959\n",
      " 0.74018106 0.7750273  0.37735301 0.79690412]\n",
      "cross_val mean score: \n",
      "0.7282887451343326\n",
      "Estimator: \n",
      "lr\n",
      "cross_val score: \n",
      "[ 0.87692088  0.8097771   0.91355854  0.74953369  0.90085273  0.63627581\n",
      "  0.88464825  0.89576788  0.4363153  -1.18087334]\n",
      "cross_val mean score: \n",
      "0.5922776832989227\n"
     ]
    }
   ],
   "source": [
    "# непонятно, как правильно совмещать кросвалидацию и holdout. \n",
    "# для меня это два независимых способа оценки качества обучения.estimators \n",
    "\n",
    "# кроссвалидация\n",
    "for est in estimators:\n",
    "    cv_results = cross_validate(est[1], Xfull, yfull, cv=10)\n",
    "    print(\"Estimator: \")\n",
    "    print(est[0])\n",
    "    print(\"cross_val score: \")\n",
    "    print(cv_results['test_score'])\n",
    "    print(\"cross_val mean score: \")\n",
    "    print(mean(cv_results['test_score']))\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimator: \n",
      "rcv\n",
      "0.8807909113996806\n",
      "Estimator: \n",
      "svr\n",
      "0.8030962274499284\n",
      "Estimator: \n",
      "lr\n",
      "0.4874106879591913\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# сравнение на holdout-выборке\n",
    "for est in estimators:\n",
    "    the_est = est[1]\n",
    "    the_est.fit(X,y)\n",
    "    print(\"Estimator: \")\n",
    "    print(est[0])\n",
    "    print(the_est.score(Xhold,yhold))\n",
    "    # print(one_rf.feature_importances_)  \n",
    "    # print(\"cross_val score: \")\n",
    "    # print(cv_results['test_score'])\n",
    "    # print(\"cross_val mean score: \")\n",
    "    # print(mean(cv_results['test_score']))\n",
    "    # # print()"
   ]
  },
  {
   "source": [
    "В итоге RidgeCV при сравнении на holdout дал бОльший score, чем стекинг.\n",
    "Значит стекинг построен неверно. Как его исправить."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}