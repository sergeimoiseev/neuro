{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('uoit': conda)"
  },
  "interpreter": {
   "hash": "26d424bfc1230b0c30211611c2aa3c9b9b27c0aba4441f1e20f124f124483991"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "# test_data = pd.read_csv('test.csv') # тестовый набор нельзя использовать: нет колонки SalePrice\n",
    "# позже раздробим data на обучающуюся и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfull = data.SalePrice\n",
    "Xfull = data.drop( labels = [\"SalePrice\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.dropna(axis='columns')\n",
    "#Находим категориальные признаки\n",
    "cat_feat = list(Xfull.dtypes[Xfull.dtypes == object].index)\n",
    "\n",
    "#отфильтруем непрерывные признаки\n",
    "num_feat = [f for f in Xfull if f not in (cat_feat + ['Id'])]\n",
    "\n",
    "# Создаем дамми-переменные для категорий\n",
    "X_dummies = pd.get_dummies(Xfull[cat_feat], columns=cat_feat)\n",
    "# dummy_test = pd.get_dummies(X_test[cat_feat], columns=cat_feat)\n",
    "\n",
    "dummy_cols = list(set(X_dummies))\n",
    "\n",
    "X_dummies = X_dummies[dummy_cols]\n",
    "# dummy_test = dummy_test[dummy_cols]\n",
    "\n",
    "# Заменяем пропуски на специальное значение -999, чтобы деревья могли их отличить\n",
    "Xfull = pd.concat([Xfull[num_feat].fillna(-999),\n",
    "                     X_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем holdout-выборку \n",
    "X, Xhold, y, yhold = train_test_split(\n",
    "    Xfull, yfull, random_state=42\n",
    ")\n",
    "X = X.reindex()\n",
    "Xhold = Xhold.reindex()\n",
    "y = y.reindex()\n",
    "yhold = yhold.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1095 entries, 1023 to 1126\nColumns: 288 entries, MSSubClass to Exterior2nd_VinylSd\ndtypes: float64(3), int64(33), uint8(252)\nmemory usage: 586.0 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random forest score:\n0.8650248449381439\nFeature importances\n[9.55092268e-04 5.01800561e-03 1.29389183e-02 5.83822050e-01\n 4.73260540e-03 8.70348794e-03 5.60615553e-03 8.93385735e-03\n 2.55760034e-02 5.74228122e-04 4.72527261e-03 3.80991674e-02\n 2.24507359e-02 4.10264963e-02 1.24024770e-04 9.95921774e-02\n 8.82134924e-04 2.12991959e-04 1.29417593e-02 5.26220994e-04\n 2.27322258e-03 7.74499918e-04 4.63390927e-03 2.78586632e-03\n 5.42355121e-03 2.36135935e-02 1.44762049e-02 4.17664974e-03\n 4.13030472e-03 6.47650125e-04 2.23528486e-04 8.81171491e-04\n 4.66632496e-04 4.19029024e-05 2.72921783e-03 1.38044315e-03\n 5.72954917e-05 5.82879802e-04 1.92239268e-04 8.52331903e-06\n 4.93259800e-06 7.55983442e-05 0.00000000e+00 1.67512103e-03\n 3.62616122e-06 3.78500082e-06 1.50096538e-05 3.31927750e-06\n 2.06734364e-05 1.96090260e-05 1.80269905e-05 1.27051216e-05\n 9.41537539e-05 1.85416050e-05 6.16715837e-08 5.66048659e-05\n 0.00000000e+00 2.42165568e-06 2.72811976e-04 3.60682174e-05\n 2.03741161e-06 5.91251896e-09 1.31830327e-04 1.81995891e-04\n 4.36907532e-09 2.32663059e-04 2.54934227e-04 8.29259791e-07\n 1.50264611e-04 1.16665897e-06 5.45022190e-04 1.01904935e-04\n 1.05936499e-03 1.24291665e-04 6.77785161e-05 1.56973674e-04\n 2.79439658e-04 5.07960667e-05 1.63671620e-04 4.33430704e-05\n 5.96381019e-04 3.62853619e-04 4.41255412e-04 3.52798435e-04\n 1.21576879e-04 6.15534195e-04 7.95615550e-06 3.79307736e-03\n 5.08526289e-05 5.45770087e-04 6.30711115e-04 2.87403687e-04\n 7.22665191e-06 4.26829957e-04 2.99678353e-04 8.13282386e-05\n 8.79167562e-05 1.84891799e-08 4.26621333e-04 5.91251794e-04\n 1.39323945e-05 1.46697138e-05 4.91154696e-04 4.99229987e-04\n 5.07355759e-04 9.07504008e-06 1.28825466e-07 6.44537010e-06\n 2.37309689e-05 1.34248991e-04 0.00000000e+00 9.10832953e-04\n 8.56751258e-05 2.74020630e-04 3.00923675e-06 2.50333414e-04\n 3.32434416e-04 5.14106059e-07 7.40080149e-06 6.30996295e-07\n 1.07849681e-05 5.37295279e-05 8.07205514e-05 3.85498338e-05\n 4.93302313e-04 2.86472728e-05 3.47153168e-05 9.49529134e-05\n 2.11490858e-04 3.06438352e-04 1.84827040e-04 7.21629788e-05\n 1.24093618e-04 1.59843156e-04 3.82783673e-04 7.54684568e-06\n 2.87855618e-04 3.77134943e-04 9.37374661e-05 9.08235887e-05\n 0.00000000e+00 0.00000000e+00 3.87133486e-09 4.98072926e-04\n 1.23765567e-04 8.76264569e-05 1.08652063e-07 1.37977675e-04\n 1.19768664e-04 1.87114270e-06 2.76197179e-04 7.30947071e-05\n 2.45850475e-04 5.66937167e-06 5.19796461e-05 4.81960616e-07\n 2.15956225e-05 3.22912470e-03 3.07631447e-04 1.57255567e-06\n 8.97751585e-05 3.54206750e-05 1.22639799e-04 2.33713071e-04\n 8.56869810e-06 1.34804508e-05 1.52496899e-05 3.58463260e-06\n 2.45280002e-05 9.02452385e-07 1.35899114e-05 3.16197748e-04\n 1.12299932e-06 1.25249173e-05 2.83717746e-05 1.20964002e-04\n 4.40793243e-06 3.02921977e-05 9.33611865e-05 6.21571659e-04\n 2.43473001e-05 6.55357012e-05 1.63414070e-04 6.17745976e-10\n 1.79811286e-04 2.08909896e-06 2.49391772e-04 1.67601190e-08\n 4.57818264e-07 1.71616192e-04 1.40316661e-05 4.07724874e-05\n 8.35400055e-07 1.01101270e-04 3.09705299e-04 4.73280132e-05\n 3.05017787e-05 1.79059711e-04 2.73344202e-04 1.34660148e-04\n 1.26401147e-07 4.17262678e-06 1.81259863e-05 1.39363198e-04\n 1.63583132e-04 8.55280746e-05 5.42659030e-04 1.08526043e-05\n 5.97890411e-05 1.89879828e-05 3.94824031e-04 6.68562530e-05\n 1.90187857e-04 4.80923907e-05 9.46267073e-06 8.42790155e-04\n 2.25102493e-04 7.28864927e-06 6.34472076e-05 1.47129596e-05\n 3.09498356e-06 4.55398644e-05 1.66299404e-05 3.18937962e-04\n 1.94503899e-04 5.26040391e-05 1.84120016e-04 5.64348627e-05\n 1.10246970e-03 4.98637274e-05 3.12403479e-05 4.44975424e-05\n 1.81738027e-05 3.63490781e-07 6.68922026e-04 5.50483151e-05\n 8.18360141e-05 2.49187714e-04 5.47514636e-06 3.07308093e-05\n 2.80833441e-08 5.16541804e-04 6.23244579e-05 7.42896354e-05\n 4.07989829e-04 7.70150673e-04 3.15376824e-04 6.11700903e-06\n 2.06820458e-04 1.37069117e-04 1.93582716e-03 6.68331862e-04\n 1.33348419e-03 1.22037253e-05 4.65404958e-08 6.52016112e-04\n 1.46900872e-05 5.59554362e-05 1.58013888e-03 1.37562007e-04\n 2.84390451e-05 1.25292880e-04 1.61655726e-03 8.90561221e-05\n 2.86886632e-07 1.83723649e-05 1.51598784e-04 5.13564253e-05\n 1.23490992e-04 4.44944528e-04 5.64144152e-04 2.73051454e-05\n 1.45320818e-09 7.30177671e-10 1.55475228e-03 8.32065061e-05\n 5.87380975e-07 2.27627236e-05 1.37612969e-04 4.29540966e-05\n 2.38083239e-06 1.32835296e-04 8.81540742e-04 5.94111337e-05\n 1.63773666e-06 1.28070172e-05 0.00000000e+00 6.15326601e-04]\n"
     ]
    }
   ],
   "source": [
    "# беру один фолд из 10 и строю на нем случайный лес, вывожу важность признаков.\n",
    "# эдакая тренировка перед стекингом\n",
    "# чуть поправил взятое отсюда\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(Xfull):\n",
    "    rf = RandomForestRegressor(verbose=False, n_jobs=-1)\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = Xfull.iloc[train_index], Xfull.iloc[test_index]\n",
    "    y_train, y_test = yfull[train_index], yfull[test_index]\n",
    "    rf.fit(X_train,y_train)\n",
    "    print(\"Random forest score:\")\n",
    "    print(rf.score(X_test,y_test))\n",
    "    print(\"Feature importances\")\n",
    "    print(rf.feature_importances_)\n",
    "    break # берем только один эксперимент, чтобы не заниматься никаким ансамблированием сейчас\n",
    "# если нужны усредненные по k-фолдам значимости параметров, можно сделать усреднением. Но не вижу смысла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8625083162376667"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# кроссвалидация одного только случайного леса - переработаный код отсюда:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "cv_results = cross_validate(rf, Xfull, yfull, cv=10)\n",
    "# sorted(cv_results.keys())\n",
    "all_scores = cv_results['test_score']\n",
    "from statistics import mean\n",
    "# средний score по 10и фолдам для случайного леса:\n",
    "mean(all_scores)\n",
    "# тоже смысла не вижу - случайный лес внутри уже делит выборку \n",
    "# в итоге у каждого из деревьев совсем мало данных, \n",
    "# оттого, наверное, и score ниже чем у простого случайного леса ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8909908042149817\n[1.70844584e-03 7.12353395e-03 1.66682379e-02 5.52650675e-01\n 3.63226063e-03 1.08022404e-02 6.70129322e-03 3.31433498e-03\n 2.75278496e-02 5.47870424e-04 5.25203538e-03 3.36189223e-02\n 2.65815432e-02 2.64522503e-02 9.30487104e-05 1.18613762e-01\n 8.66153121e-04 7.81756296e-05 2.67507898e-03 8.34392569e-04\n 1.30884392e-03 3.81299543e-04 8.67458792e-03 4.93596504e-03\n 7.32163190e-03 2.63805052e-02 1.46945850e-02 5.38280473e-03\n 4.95373940e-03 8.23253341e-04 2.23397829e-04 2.41848775e-03\n 2.03330567e-03 6.13724076e-05 3.95380827e-03 1.32477589e-03\n 2.97689031e-04 8.32226872e-04 4.76812218e-04 1.87011894e-05\n 4.14514534e-06 4.53554395e-05 2.47005356e-05 2.07866823e-03\n 1.10903238e-05 1.86234801e-06 1.95216815e-05 7.59781989e-05\n 1.57870110e-04 2.23997567e-05 1.83416397e-05 5.92043053e-06\n 8.35628654e-05 4.07039895e-05 2.49078929e-07 2.33293997e-04\n 0.00000000e+00 5.10091500e-07 2.10123319e-04 5.10677769e-05\n 8.58689023e-09 3.46502112e-09 3.48280530e-04 3.77320416e-04\n 3.98561743e-07 4.10441765e-04 4.02168877e-04 7.91626898e-07\n 2.03400077e-04 1.84448484e-06 2.44523121e-04 1.13175864e-04\n 1.14592348e-03 5.81578402e-05 3.26187890e-05 1.53225063e-04\n 2.06180846e-04 1.06190977e-05 3.24448097e-04 5.79453922e-06\n 5.84413864e-04 2.04678363e-04 5.77080103e-04 7.62820356e-04\n 1.66687835e-04 1.30912499e-03 1.32402367e-05 7.34256894e-03\n 2.23681371e-04 3.57282228e-04 2.60895699e-04 3.39904879e-04\n 4.76247108e-04 2.61538083e-04 2.64942913e-04 3.70795341e-04\n 3.42107760e-05 1.31472487e-07 3.36584671e-04 4.66618818e-04\n 9.84009879e-06 1.30543671e-05 6.23953306e-04 2.85495577e-04\n 8.64015468e-04 1.05893095e-07 1.58968231e-11 0.00000000e+00\n 2.12592934e-05 2.38070077e-04 0.00000000e+00 1.67900322e-03\n 2.76538588e-05 3.26325281e-04 5.79502295e-07 3.30097402e-04\n 9.09322154e-04 0.00000000e+00 1.93108922e-06 3.32074429e-06\n 1.60082106e-06 1.34687453e-04 8.27118662e-05 5.26652076e-05\n 4.66192394e-04 1.58802216e-05 8.07746490e-05 1.09305127e-04\n 1.03227715e-03 3.73637773e-04 3.35449508e-04 4.97899152e-04\n 6.35816768e-05 1.71397234e-04 8.05619696e-04 1.64325916e-05\n 4.46803626e-04 1.80379862e-04 1.29768203e-04 5.11765099e-05\n 0.00000000e+00 2.80837285e-07 3.27998303e-08 5.61079929e-04\n 7.00477981e-05 4.67717125e-05 4.23443998e-06 1.75154916e-04\n 4.19312067e-04 1.60501524e-05 5.08116755e-04 1.13864974e-04\n 3.36287368e-04 6.18003800e-06 4.74254879e-05 5.52234812e-07\n 3.05440494e-06 2.77322948e-03 6.25187221e-04 1.27851230e-05\n 3.03485823e-05 4.67078108e-05 1.01118965e-04 1.94671386e-04\n 0.00000000e+00 7.29902283e-05 6.48246087e-05 2.63734604e-06\n 8.32228480e-05 5.83718206e-06 7.57079355e-06 3.31919469e-04\n 1.63454183e-07 2.58253298e-06 3.88296536e-08 8.60395897e-05\n 1.03899491e-08 2.56192623e-05 3.92824650e-04 6.15449122e-04\n 2.46650462e-05 3.00809466e-05 1.86977773e-04 1.08667867e-07\n 8.73112268e-04 9.76733740e-07 2.42275481e-04 3.80475459e-08\n 0.00000000e+00 1.47853591e-04 3.12164613e-05 4.57954728e-05\n 4.92277458e-07 9.52795451e-05 2.89452491e-04 5.62031395e-05\n 5.91034722e-05 3.28195850e-04 1.56086490e-04 1.27476310e-04\n 3.67731344e-06 4.10130282e-05 2.81793109e-05 5.87780710e-05\n 2.42381127e-06 5.41351649e-05 1.39120615e-03 8.92432747e-06\n 9.35276941e-05 1.75522091e-05 4.62513021e-04 4.99182513e-05\n 3.74368963e-04 5.01075216e-05 1.06494617e-04 6.14081520e-04\n 3.54714366e-04 2.21367615e-06 2.37554682e-04 1.06332552e-05\n 2.62678843e-06 1.52208640e-04 2.74587263e-05 3.78201307e-04\n 1.58825430e-04 5.75666103e-05 8.70830264e-05 0.00000000e+00\n 1.16932785e-03 5.76940001e-05 2.82933289e-05 1.45455354e-05\n 1.23223037e-05 9.92042104e-07 6.15881749e-04 5.71729434e-05\n 6.07536687e-05 3.20526184e-04 4.28721608e-07 1.78922171e-05\n 6.28352652e-09 6.33600832e-04 7.84464288e-05 8.82365357e-05\n 5.67530581e-04 1.03229304e-03 4.52467349e-04 7.71475004e-06\n 1.71919968e-04 1.85136363e-04 1.54817368e-03 1.52335052e-04\n 1.59957080e-03 1.14450859e-05 0.00000000e+00 3.97907273e-04\n 2.98258805e-06 7.69611694e-05 2.04461898e-03 1.19272517e-04\n 6.55557968e-05 7.96504116e-05 1.96802451e-03 4.32963375e-05\n 0.00000000e+00 1.24454577e-05 4.68129445e-04 5.75132183e-05\n 1.29694762e-04 8.65274985e-04 8.94941438e-04 1.09334999e-05\n 2.29646450e-05 1.27259559e-06 2.44446287e-03 3.72874713e-05\n 1.16495935e-05 2.33640286e-05 1.19090146e-04 1.11572766e-04\n 7.04910709e-06 5.36149367e-05 1.25924280e-03 1.19471026e-04\n 7.15582330e-06 2.57281976e-05 0.00000000e+00 2.28258330e-04]\n"
     ]
    }
   ],
   "source": [
    "# Один случайный лес - учим на всем, кроме holdout, проверяем на holdout.\n",
    "# Плюс выводим важность признаков\n",
    "# Интересно, насколько скор будет отличаться у cv и такого подхода \n",
    "one_rf = RandomForestRegressor(verbose=False, n_jobs=-1)\n",
    "one_rf.fit(X,y)\n",
    "print(one_rf.score(Xhold,yhold))\n",
    "print(one_rf.feature_importances_)\n",
    "# скор получился тут су"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9013787553552302"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# на трех моделях строим стекинг, \n",
    "# а потом считаем скор каждой из них в отдельности\n",
    "# непонятно, как правильно совмещать кросвалидацию и holdout. \n",
    "# для меня это два независимых способа оценки качества обучения.estimators\n",
    "\n",
    "# отсюда код взят и доработан\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html?highlight=regressor#sklearn.ensemble.StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV, SGDRegressor, LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# X, y = load_diabetes(return_X_y=True)\n",
    "estimators = [\n",
    "    ('rcv', RidgeCV()),\n",
    "    ('svr', LinearSVR(random_state=42)),\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    # ('lr', LinearRegression())\n",
    "    # ('sgd', SGDRegressor(random_state=42))\n",
    "]\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RidgeCV(),\n",
    "    cv=10,\n",
    ")\n",
    "\n",
    "reg.fit(X, y).score(Xhold, yhold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimator: \n",
      "rcv\n",
      "cross_val score: \n",
      "[0.91089043 0.90884634 0.89996691 0.78113865 0.88449541 0.88597101\n",
      " 0.86924554 0.88814094 0.56787695 0.88265082]\n",
      "cross_val mean score: \n",
      "0.84792230118371\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "Estimator: \n",
      "svr\n",
      "cross_val score: \n",
      "[0.80158092 0.77074654 0.82657469 0.66400414 0.76824609 0.76226959\n",
      " 0.74018106 0.7750273  0.37735301 0.79690412]\n",
      "cross_val mean score: \n",
      "0.7282887451343326\n",
      "Estimator: \n",
      "lr\n",
      "cross_val score: \n",
      "[ 0.87692088  0.8097771   0.91355854  0.74953369  0.90085273  0.63627581\n",
      "  0.88464825  0.89576788  0.4363153  -1.18087334]\n",
      "cross_val mean score: \n",
      "0.5922776832989227\n"
     ]
    }
   ],
   "source": [
    "# непонятно, как правильно совмещать кросвалидацию и holdout. \n",
    "# для меня это два независимых способа оценки качества обучения.estimators \n",
    "\n",
    "# кроссвалидация\n",
    "for est in estimators:\n",
    "    cv_results = cross_validate(est[1], Xfull, yfull, cv=10)\n",
    "    print(\"Estimator: \")\n",
    "    print(est[0])\n",
    "    print(\"cross_val score: \")\n",
    "    print(cv_results['test_score'])\n",
    "    print(\"cross_val mean score: \")\n",
    "    print(mean(cv_results['test_score']))\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimator: \n",
      "rcv\n",
      "0.8807907617616811\n",
      "C:\\Users\\Sergei\\anaconda3\\envs\\uoit\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "Estimator: \n",
      "svr\n",
      "0.803096227449928\n",
      "Estimator: \n",
      "rf\n",
      "0.8860695399769015\n"
     ]
    }
   ],
   "source": [
    "# сравнение на holdout-выборке\n",
    "for est in estimators:\n",
    "    the_est = est[1]\n",
    "    the_est.fit(X,y)\n",
    "    print(\"Estimator: \")\n",
    "    print(est[0])\n",
    "    print(the_est.score(Xhold,yhold))\n",
    "    # print(one_rf.feature_importances_)  \n",
    "    # print(\"cross_val score: \")\n",
    "    # print(cv_results['test_score'])\n",
    "    # print(\"cross_val mean score: \")\n",
    "    # print(mean(cv_results['test_score']))\n",
    "    # # print()"
   ]
  },
  {
   "source": [
    "В первой попытке RidgeCV при сравнении на holdout дал бОльший score, чем стекинг.\n",
    "Значит стекинг был построен неверно. Преподаватель посоветовал ставить сложные модели на первый слой (в estimators), а модель второго уровня брать попроще.\n",
    "В результате стэкинг дал score 0.9, а все estimators отдельно - меньшие score."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}